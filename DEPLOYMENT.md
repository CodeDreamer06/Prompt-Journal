# Deployment Instructions

## ğŸš€ Deploy to Vercel

### Option 1: Vercel CLI (Recommended)

1. **Install Vercel CLI**
   ```bash
   npm i -g vercel
   ```

2. **Login to Vercel**
   ```bash
   vercel login
   ```

3. **Deploy**
   ```bash
   vercel --prod
   ```

4. **Set Environment Variables**
   ```bash
   vercel env add NEXT_PUBLIC_ADMIN_PASSWORD
   ```
   Enter your secure admin password when prompted.

### Option 2: Vercel Dashboard

1. Go to [vercel.com](https://vercel.com)
2. Click "New Project"
3. Import from GitHub: `https://github.com/CodeDreamer06/Prompt-Journal.git`
4. Add environment variable:
   - Name: `NEXT_PUBLIC_ADMIN_PASSWORD`
   - Value: Your secure admin password
5. Deploy!

## ğŸ”§ Local Development

1. **Clone and install**
   ```bash
   git clone https://github.com/CodeDreamer06/Prompt-Journal.git
   cd Prompt-Journal
   npm install
   ```

2. **Set up environment**
   ```bash
   cp .env.example .env.local
   ```
   Edit `.env.local` and set your admin password.

3. **Run development server**
   ```bash
   npm run dev
   ```

4. **Access the application**
   - Public site: http://localhost:3000
   - Admin panel: http://localhost:3000/admin

## ğŸ¯ First Steps After Deployment

1. **Access Admin Panel**
   - Go to `/admin` on your deployed site
   - Enter your admin password

2. **Create Your First Chat**
   - Click "New Chat"
   - Fill in title, select LLM, add tags
   - Paste your conversation in the markdown format:
     ```markdown
     ### ğŸ§‘â€ğŸ’» User
     
     Your question here
     
     ---
     
     ### ğŸ¤– Assistant
     
     AI response here
     ```
   - Check "Published" and save

3. **Share Your Blog**
   - Your conversations will appear on the homepage
   - Each chat gets a clean URL like `/chat/your-conversation-title`
   - Share individual conversations or the main blog

## ğŸ”’ Security Notes

- Admin password is stored as an environment variable
- No sensitive data in the codebase
- All data stored in browser localStorage
- Use export/import for backups

## ğŸ“± Features Overview

### Public Features
- âœ… Clean blog homepage
- âœ… Search and filter conversations
- âœ… LLM-specific styling (ChatGPT, Claude, Gemini, Custom)
- âœ… Responsive design
- âœ… Dark mode auto-detection
- âœ… Individual chat pages with clean URLs

### Admin Features
- âœ… Password-protected admin panel
- âœ… Create/edit/delete conversations
- âœ… Draft and publish system
- âœ… Tag management
- âœ… Export/import functionality
- âœ… Live preview while editing

### Technical Features
- âœ… Next.js 15 with App Router
- âœ… Tailwind CSS 4
- âœ… TypeScript
- âœ… Markdown rendering with syntax highlighting
- âœ… SEO optimized
- âœ… Static site generation

## ğŸ¨ Customization

### Adding New LLMs
Edit `lib/llms.ts` to add new LLM configurations:

```typescript
export const LLM_CONFIGS = {
  // ... existing configs
  'your-llm': {
    name: 'Your LLM',
    logo: 'ğŸš€',
    color: 'border-purple-500',
    textColor: 'text-purple-600 dark:text-purple-400',
    bgColor: 'bg-purple-50 dark:bg-purple-950'
  }
}
```

### Styling
- Main styles: `app/globals.css`
- Tailwind config: Uses Tailwind CSS 4 with automatic dark mode
- Component styles: Inline with Tailwind classes

## ğŸ“Š Analytics (Optional)

To add Google Analytics:
1. Add `NEXT_PUBLIC_GA_ID` to your environment variables
2. The tracking code is already set up in the layout

## ğŸ”„ Backup & Migration

### Export Data
- Use the "Export All" button in admin panel
- Downloads JSON file with all conversations

### Import Data
- Use the "Import" button in admin panel
- Upload previously exported JSON file

## ğŸ› Troubleshooting

### Build Issues
- Ensure Node.js 18+ is installed
- Run `npm install` to update dependencies
- Check TypeScript errors with `npm run build`

### Admin Access Issues
- Verify `NEXT_PUBLIC_ADMIN_PASSWORD` is set correctly
- Clear browser session storage if needed
- Check browser console for errors

### Deployment Issues
- Ensure environment variables are set in Vercel dashboard
- Check build logs for errors
- Verify GitHub repository is public or Vercel has access

## ğŸ‰ You're All Set!

Your Prompt Journal is now ready to share your LLM conversations with the world!